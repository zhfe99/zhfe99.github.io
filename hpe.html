<!DOCTYPE html><html><head><title>Human Pose Estimation</title><link rel="icon" href="img/head.icon"><link rel="stylesheet" href="http://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/css/bootstrap.min.css"><link rel="stylesheet" href="s/f-zhou.css" type="text/css"></head><body><div id="header"><div id="nav" class="container"><ul><li><a class="item" href="index.html">FEATURED</a></li><li><a class="item" href="pub.html">PUBLICATIONS</a></li><li><a class="item" href="soft.html">SOFTWARES</a></li><li><a class="item" href="bio.html">ABOUT</a></li></ul></div></div><div class="container container_top"><h1>Spatio-temporal Matching for Human Pose Estimation</h1><div class="proj_overview"><img src="hpe/overview.png"><p class="main">Detection and tracking of humans in three videos using STM.</p><p class="more">STM extracts trajectories in video (gray lines) and selects   a subset of trajectories (a) that match with the 3D motion capture   model (b) learned from the CMU motion capture data set.</p></div><div class="line_wrap"><div class="line_content"><h2>People</h2></div></div><div class="sec_content"><ul class="li_col"><li>Feng Zhou <span class="place">(CMU)</span></li><li><a href="http://www.cs.cmu.edu/~ftorre" class="level1">Fernando De la Torre</a> <span class="place">(CMU)</span></li></ul></div><div class="line_wrap"><div class="line_content"><h2>Introduction</h2></div></div><div class="sec_content"><p>Detection and tracking humans in videos have been   long-standing problems in computer vision. Most successful   approaches (e.g., deformable parts models) heavily rely on   discriminative models to build appearance detectors for body joints   and generative models to constrain possible body   configurations. While these 2D models have been successfully applied   to images (and with less success to videos), a major challenge is to   generalize these models to cope with camera views. In order to   achieve view-invariance, these 2D models typically require a large   amount of training data across views that is difficult to gather and   time-consuming to label. Unlike existing 2D models, this paper   formulates the problem of human detection in videos as   spatio-temporal matching (STM) between a 3D motion capture model and   trajectories in videos. Our algorithm estimates the camera view and   selects a subset of tracked trajectories that matches the motion of   the 3D model. The STM is efficiently solved with linear   programming, and it is robust to tracking mismatches, occlusions and   outliers.</p></div><div class="line_wrap"><div class="line_content"><h2>Videos</h2></div></div><div class="sec_content"><div class="video_item"><div class="video_main"><iframe src="//player.vimeo.com/video/104238249?title=0&amp;byline=0&amp;portrait=0" width="500" height="292" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe></div><div class="video_info hei_292"><p>This spotlight summarizes the main problem and our contributions.</p><p>Download the [<a href="hpe/2014_ECCV_STM_Spotlight.mp4" class="level2">Video</a>&nbsp;<span class="pub_info_size">40MB</span>].</p></div></div><div class="video_item"><div class="video_main"><iframe src="//player.vimeo.com/video/100444304?title=0&amp;byline=0&amp;portrait=0" width="500" height="292" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe></div><div class="video_info hei_292"><p>This video shows the details of computing STM on three                 datasets, <a href="http://mocap.cs.cmu.edu"                 class="level3">CMU Motion Capture Database</a>,               <a href="http://tele-immersion.citris-uc.org/berkeley_mhad" class="level3">Berkeley MHAD Database</a>,               and <a href="http://vision.imar.ro/human3.6m/description.php" class="level3">Human3.6M Database</a>.</p><p>Download the [<a href="hpe/2014_ECCV_STM.mp4" class="level2">Video</a>&nbsp;<span class="pub_info_size">51MB</span>].</p></div></div><div class="video_item"><div class="video_main"><iframe src="https://player.vimeo.com/video/147960268?title=0&amp;byline=0&amp;portrait=0" width="500" height="187" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe></div><div class="video_info hei_187"><p>The associated video for the first sequence shown in Fig.8a of <a href="#ref_stm_pami"><span>[</span>2<span>]</span></a>.</p><p>Download the [<a href="hpe/fig8a_vdo1.avi" class="level2">Video</a>&nbsp;<span class="pub_info_size">6MB</span>].</p></div></div><div class="video_item"><div class="video_main"><iframe src="https://player.vimeo.com/video/147961034?title=0&amp;byline=0&amp;portrait=0" width="500" height="187" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe></div><div class="video_info hei_187"><p>The associated video for the second sequence shown in Fig.8a of <a href="#ref_stm_pami"><span>[</span>2<span>]</span></a>.</p><p>Download the [<a href="hpe/fig8a_vdo2.avi" class="level2">Video</a>&nbsp;<span class="pub_info_size">7MB</span>].</p></div></div><div class="video_item"><div class="video_main"><iframe src="https://player.vimeo.com/video/147961255?title=0&amp;byline=0&amp;portrait=0" width="500" height="187" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe></div><div class="video_info hei_187"><p>The associated video for the third sequence shown in Fig.8a of <a href="#ref_stm_pami"><span>[</span>2<span>]</span></a>.</p><p>Download the [<a href="hpe/fig8a_vdo3.avi" class="level2">Video</a>&nbsp;<span class="pub_info_size">22MB</span>].</p></div></div><div class="video_item"><div class="video_main"><iframe src="https://player.vimeo.com/video/147961379?title=0&amp;byline=0&amp;portrait=0" width="500" height="188" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe></div><div class="video_info hei_187"><p>The associated video for the first sequence shown in Fig.11a of <a href="#ref_stm_pami"><span>[</span>2<span>]</span></a>.</p><p>Download the [<a href="hpe/fig11a_vdo1.avi" class="level2">Video</a>&nbsp;<span class="pub_info_size">128MB</span>].</p></div></div><div class="video_item"><div class="video_main"><iframe src="https://player.vimeo.com/video/147961546?title=0&amp;byline=0&amp;portrait=0" width="500" height="188" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe></div><div class="video_info hei_187"><p>The associated video for the second sequence shown in Fig.11a of <a href="#ref_stm_pami"><span>[</span>2<span>]</span></a>.</p><p>Download the [<a href="hpe/fig11a_vdo2.avi" class="level2">Video</a>&nbsp;<span class="pub_info_size">149MB</span>].</p></div></div></div><div class="line_wrap"><div class="line_content"><h2>Publications</h2></div></div><div class="sec_content"><ul class="sec_pub"><li><div class="index" id="ref_stm">[1]</div><div class="detail"><span class="pub_info_title">Spatio-temporal Matching for Human Detection in Video</span><div class="pub_info_other">European Conference on Computer Vision (ECCV), 2014<br>F. Zhou and                 <a href="http://www.cs.cmu.edu/~ftorre" class="level1">F. De la Torre</a></div><div class="pub_info_link">[<a href="hpe/2014_ECCV_STM.pdf" class="level2">Paper</a>&nbsp;<span class="pub_info_size">20MB</span>]                 [<a href="hpe/2014_ECCV_STM.pptx" class="level2">Slides</a>&nbsp;<span class="pub_info_size">96MB</span>]</div></div></li><li><div class="index" id="ref_stm_pami">[2]</div><div class="detail"><span class="pub_info_title">Spatio-temporal Matching for Human Pose Esimation in Video</span><div class="pub_info_other">IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI), 38(8):1492-1504, 2016<br>F. Zhou and                 <a href="http://www.cs.cmu.edu/~ftorre" class="level1">F. De la Torre</a></div><div class="pub_info_link">[<a href="hpe/2015_PAMI_STM.pdf" class="level2">Paper</a>&nbsp;<span class="pub_info_size">25MB</span>]</div></div></li></ul></div></div><div class="footer"></div><!-- js --><script src="//code.jquery.com/jquery-1.11.3.min.js"></script><script src="http://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script><script type="text/javascript" src="s/retina.js"></script><script type="text/javascript">var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");       document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));</script><script type="text/javascript">try {       var pageTracker = _gat._getTracker("UA-5376400-1");       pageTracker._trackPageview();       } catch(err) {}</script></body></html>